% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/MSmix_functions_package.R
\name{fitMSmoe}
\alias{fitMSmoe}
\alias{print.emMSmoe}
\title{MLE of MoE of Mallows models with Spearman distance via EMM algorithms}
\usage{
fitMSmoe(
  rankings,
  X,
  n_clust = 2,
  n_start = 1,
  n_iter = 200,
  mc_em = FALSE,
  eps = 10^(-6),
  init = list(list(rho = NULL, theta = NULL, betas = NULL))[rep(1, n_start)],
  plot_log_lik = FALSE,
  comp_log_lik_part = FALSE,
  plot_log_lik_part = FALSE,
  parallel = FALSE,
  theta_max = 3,
  theta_tol = 1e-05,
  theta_tune = 1,
  subset = NULL,
  item_names = NULL
)

\method{print}{emMSmoe}(x, ...)
}
\arguments{
\item{rankings}{Integer \eqn{N}\eqn{\times}{x}\eqn{n} matrix or data frame
with partial rankings in each row. Missing positions must be coded as \code{NA}.}

\item{X}{Numeric \eqn{N}\eqn{\times}{x}\eqn{H+1} design matrix with covariate profiles in each row. The first column must be the constant.}

\item{n_clust}{Number of mixture components. Defaults to 1.}

\item{n_start}{Number of starting points. Defaults to 1.}

\item{n_iter}{Maximum number of EM iterations. Defaults to 200.}

\item{mc_em}{Logical: whether the Monte Carlo EM algorithm must be used for MLE on partial rankings completion, see Details. Ignored when \code{rankings} does not contain any partial sequence. Defaults to \code{FALSE}.}

\item{eps}{Positive tolerance value for the convergence of the EM algorithm. Defaults to \eqn{10^{-6}}.}

\item{init}{List of \code{n_start} lists with the starting values of the parameters to initialize the EM algorithm. Each list must contain three named objects, namely: 1) \code{rho}: integer \eqn{G}\eqn{\times}{x}\eqn{n} matrix with the component-specific consensus rankings in each row; 2) \code{theta}: numeric vector of \eqn{G} non-negative component-specific precision parameters; 3) \code{betas}: numeric \eqn{G}\eqn{\times}{x}\eqn{H+1} matrix of regression coefficients. Defaults to \code{NULL}, meaning that the starting points are automatically generated from the uniform distribution.}

\item{plot_log_lik}{Logical: whether the iterative log-likelihood values (based on full or augmented rankings) must be plotted. Defaults to \code{FALSE}.}

\item{comp_log_lik_part}{Logical: whether the maximized observed-data log-likelihood value (based on partial rankings) must be returned. Ignored when \code{rankings} does not contain any partial sequence or \code{\link{data_augmentation}} cannot be applied. See Details. Defaults to \code{FALSE}.}

\item{plot_log_lik_part}{Logical: whether the iterative observed-data log-likelihood values (based on partial rankings) must be plotted. Ignored when \code{rankings} does not contain any partial sequence. In the presence of partial rankings, this argument is ignored when \code{comp_log_lik_part = FALSE} or \code{\link{data_augmentation}} cannot be applied. Defaults to \code{FALSE}.}

\item{parallel}{Logical: whether parallelization over multiple initializations must be used. Defaults to \code{FALSE}.}

\item{theta_max}{Positive upper bound for the precision parameters. Defaults to 3.}

\item{theta_tol}{Positive convergence tolerance for the Mstep on theta. Defaults to \eqn{10^{-5}}.}

\item{theta_tune}{Positive tuning constant affecting the precision parameters in the Monte Carlo step. Ignored when \code{rankings} does not contain any partial sequence or \code{mc_em = FALSE}. Defaults to 1.}

\item{subset}{Optional logical or integer vector specifying the subset of observations, i.e. rows of the \code{rankings}, to be kept. Missing values are taken as \code{FALSE}.}

\item{item_names}{Character vector for the names of the items. Defaults to \code{NULL}, meaning that \code{colnames(rankings)} is used and, if not available, \code{item_names} is set equal to \code{"Item1","Item2",...}.}

\item{x}{An object of class \code{"emMSmoe"} returned by \code{\link{fitMSmoe}}.}

\item{...}{Further arguments passed to or from other methods (not used).}
}
\value{
An object of class \code{"emMSmoe"}, namely a list with the following named components:
\describe{
\item{\code{mod}}{List of named objects describing the best fitted model in terms of maximized log-likelihood over the \code{n_start} initializations. See Details.}
\item{\code{max_log_lik}}{Maximized log-likelihood values for each initialization.}
\item{\code{partial_data}}{Logical: whether the dataset includes some partially-ranked sequences.}
\item{\code{convergence}}{Binary convergence indicators of the EM algorithm for each initialization: 1 = convergence has been achieved, 0 = otherwise.}
\item{\code{record}}{Best log-likelihood values sequentially achieved over the \code{n_start} initializations.}
\item{\code{em_settings}}{List of settings used to fit the model.}
\item{\code{call}}{The matched call.}

}

The \code{mod} sublist contains the following named objects:
\describe{
\item{\code{rho}}{Integer \eqn{G}\eqn{\times}{x}\eqn{n} matrix with the MLEs of the component-specific consensus rankings in each row.}
\item{\code{theta}}{Numeric vector with the MLEs of the \eqn{G} component-specific precision parameters.}
\item{\code{betas}}{Numeric matrix with the MLEs of the regression coefficients.}
\item{\code{z_hat}}{Numeric \eqn{N}\eqn{\times}{x}\eqn{G} matrix of the estimated posterior component membership probabilities. Returned when \code{n_clust > 1}, otherwise \code{NULL}.}
\item{\code{map_classification}}{Integer vector of \eqn{N} mixture component memberships based on the MAP allocation from the \code{z_hat} matrix. Returned when \code{n_clust > 1}, otherwise \code{NULL}.}
\item{\code{log_lik}}{Numeric vector of the log-likelihood values (based on full or augmented rankings) at each iteration.}
\item{\code{best_log_lik}}{Maximized log-likelihood value (based on full or augmented rankings) of the fitted model.}
\item{\code{bic}}{BIC value of the fitted model based on \code{best_log_lik}.}
\item{\code{log_lik_part}}{Numeric vector of the observed-data log-likelihood values (based on partial rankings) at each iteration. Returned when \code{rankings} contains some partial sequences that can be completed with \code{data_augmentation} and \code{plot_log_lik_part = TRUE}, otherwise \code{NULL}. See Details.}
\item{\code{best_log_lik_part}}{Maximized observed-data log-likelihood value (based on partial rankings) of the fitted model. Returned when \code{rankings} contains some partial sequences that can be completed with \code{data_augmentation}, otherwise \code{NULL}. See Details.}
\item{\code{bic_part}}{BIC value of the fitted model based on \code{best_log_lik_part}. Returned when \code{rankings} contains some partial sequences that can be completed with \code{\link{data_augmentation}}, otherwise \code{NULL}. See Details.}
\item{\code{conv}}{Binary convergence indicator of the best fitted model: 1 = convergence has been achieved, 0 = otherwise.}
\item{\code{augmented_rankings}}{Integer \eqn{N}\eqn{\times}{x}\eqn{n} matrix with rankings completed through the Monte Carlo step in each row. Returned when \code{rankings} contains some partial sequences and \code{mc_em = TRUE}, otherwise \code{NULL}.}
}
}
\description{
Perform the MLE of mixtures of experts of Mallows model with Spearman distance
on full rankings via an EM algorithm augmented with a MM step.

\code{print} method for class \code{"emMSmoe"}.
}
\details{
The EM algorithms are launched from \code{n_start} initializations and the best solution in terms of maximized
log-likelihood value (based on full or augmented rankings) is returned.
}
\examples{
## Example 1. Fit the 3-component mixture of Mallows models with Spearman distance
## to the Antifragility dataset.
r_antifrag <- ranks_antifragility[, 1:7]
set.seed(123)
mms_fit <- fitMSmix(rankings = r_antifrag, n_clust = 3, n_start = 10)
mms_fit$mod$rho; mms_fit$mod$theta; mms_fit$mod$weights

## Example 2. Fit the Mallows model with Spearman distance
## to simulated partial rankings through data augmentation.
rank_data <- rbind(c(NA, 4, NA, 1, NA), c(NA, NA, NA, NA, 1), c(2, NA, 1, NA, 3),
                   c(4, 2, 3, 5, 1), c(NA, 4, 1, 3, 2))
mms_fit <- fitMSmix(rankings = rank_data, n_start = 10)
mms_fit$mod$rho; mms_fit$mod$theta

## Example 3. Fit the Mallows model with Spearman distance
## to the Reading genres dataset through Monte Carlo EM.
top5_read <- ranks_read_genres[, 1:11]
mms_fit <- fitMSmix(rankings = top5_read, n_start = 10, mc_em = TRUE)
mms_fit$mod$rho; mms_fit$mod$theta

}
\references{
Crispino M, Modugno L and Mollica C (2025). Integrating covariates in mixtures of Mallows models with Spearman distance for analyzing preference rankings.

Crispino M, Mollica C and Modugno L (2025). MSmix: An R Package for clustering partial rankings via mixtures of Mallows Models with Spearman distance. \emph{(submitted)}

Crispino M, Mollica C, Astuti V and Tardella L (2023). Efficient and accurate inference for mixtures of Mallows models with Spearman distance. \emph{Statistics and Computing}, \bold{33}(98), DOI: 10.1007/s11222-023-10266-8.

Sørensen Ø, Crispino M, Liu Q and Vitelli V (2020). BayesMallows: An R Package for the Bayesian Mallows Model. \emph{The R Journal}, \bold{12}(1), pages 324--342, DOI: 10.32614/RJ-2020-026.

Beckett LA (1993). Maximum likelihood estimation in Mallows’s model using partially ranked data. In \emph{Probability models and statistical analyses for ranking data}, pages 92--107. Springer New York.
}
\seealso{
\code{\link{summary.emMSmix}}, \code{\link{plot.emMSmix}}
}
